{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "total_result = dict() # to store the result of diferent approaches "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('smoking data/competition_format/x_train.csv')\n",
    "y_train = pd.read_csv('smoking data/competition_format/y_train.csv')['smoking']\n",
    "x_test = pd.read_csv('smoking data/competition_format/x_test.csv')\n",
    "y_test= pd.read_csv('smoking data/competition_format/y_test.csv')['smoking'].squeeze()\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "                                                    x_train, \n",
    "                                                    y_train,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state = 8) \n",
    "\n",
    "all_data = (x_train, x_test, x_valid, y_train, y_test, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some functions \n",
    "from sklearn import preprocessing\n",
    "\n",
    "def calculate_acc(y_pred, y_test):\n",
    "      return np.mean(y_pred == y_test)\n",
    "\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "def labalize(data):\n",
    "    try:\n",
    "        for column_name in data.columns:\n",
    "            if data[column_name].dtype == object:\n",
    "                data[column_name] = le.fit_transform(data[column_name])\n",
    "            else:\n",
    "                pass\n",
    "    except:\n",
    "        pass\n",
    "[labalize(d) for d in all_data]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <th>waist(cm)</th>\n",
       "      <th>eyesight(left)</th>\n",
       "      <th>eyesight(right)</th>\n",
       "      <th>hearing(left)</th>\n",
       "      <th>hearing(right)</th>\n",
       "      <th>...</th>\n",
       "      <th>LDL</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>Urine protein</th>\n",
       "      <th>serum creatinine</th>\n",
       "      <th>AST</th>\n",
       "      <th>ALT</th>\n",
       "      <th>Gtp</th>\n",
       "      <th>oral</th>\n",
       "      <th>dental caries</th>\n",
       "      <th>tartar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>65</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>165</td>\n",
       "      <td>90</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>165.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>170</td>\n",
       "      <td>75</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>25.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>175</td>\n",
       "      <td>70</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>160</td>\n",
       "      <td>75</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>132.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11134</th>\n",
       "      <td>55676</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>170</td>\n",
       "      <td>65</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>118.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11135</th>\n",
       "      <td>55681</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11136</th>\n",
       "      <td>55683</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "      <td>68.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11137</th>\n",
       "      <td>55684</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>146.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11138</th>\n",
       "      <td>55691</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>160</td>\n",
       "      <td>65</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11139 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  gender  age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  \\\n",
       "0          8       1   80         160          65       91.0             0.9   \n",
       "1         17       1   30         165          90       98.0             1.5   \n",
       "2         20       1   40         170          75       81.0             1.5   \n",
       "3         24       1   35         175          70       80.0             1.0   \n",
       "4         25       1   35         160          75       93.0             1.0   \n",
       "...      ...     ...  ...         ...         ...        ...             ...   \n",
       "11134  55676       0   40         170          65       75.0             0.9   \n",
       "11135  55681       0   45         160          50       70.0             1.2   \n",
       "11136  55683       0   55         160          50       68.5             1.0   \n",
       "11137  55684       1   60         165          60       78.0             0.8   \n",
       "11138  55691       1   55         160          65       85.0             0.9   \n",
       "\n",
       "       eyesight(right)  hearing(left)  hearing(right)  ...    LDL  hemoglobin  \\\n",
       "0                  0.7            1.0             1.0  ...   94.0        14.5   \n",
       "1                  1.5            1.0             1.0  ...  165.0        15.6   \n",
       "2                  1.5            1.0             1.0  ...   98.0        16.4   \n",
       "3                  1.0            1.0             1.0  ...  160.0        15.3   \n",
       "4                  1.2            1.0             1.0  ...  132.0        14.7   \n",
       "...                ...            ...             ...  ...    ...         ...   \n",
       "11134              0.9            1.0             1.0  ...  118.0        12.3   \n",
       "11135              1.2            1.0             1.0  ...   79.0        14.0   \n",
       "11136              1.2            1.0             1.0  ...   63.0        12.4   \n",
       "11137              1.0            1.0             1.0  ...  146.0        14.4   \n",
       "11138              0.7            1.0             1.0  ...  150.0        15.0   \n",
       "\n",
       "       Urine protein  serum creatinine   AST   ALT   Gtp  oral  dental caries  \\\n",
       "0                1.0               1.0  29.0  19.0  39.0     0            0.0   \n",
       "1                1.0               0.9  20.0  37.0  34.0     0            0.0   \n",
       "2                1.0               0.7  25.0  32.0  73.0     0            0.0   \n",
       "3                1.0               0.7  30.0  55.0  50.0     0            0.0   \n",
       "4                1.0               1.1  35.0  58.0  56.0     0            0.0   \n",
       "...              ...               ...   ...   ...   ...   ...            ...   \n",
       "11134            1.0               0.6  14.0   7.0  10.0     0            1.0   \n",
       "11135            1.0               0.9  20.0  12.0  14.0     0            0.0   \n",
       "11136            1.0               0.5  17.0  11.0  12.0     0            0.0   \n",
       "11137            1.0               0.7  20.0  19.0  18.0     0            0.0   \n",
       "11138            1.0               0.8  26.0  29.0  41.0     0            0.0   \n",
       "\n",
       "       tartar  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "11134       1  \n",
       "11135       1  \n",
       "11136       0  \n",
       "11137       0  \n",
       "11138       1  \n",
       "\n",
       "[11139 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, x_test.shape, x_valid.shape,y_test.shape, y_test.shape, y_valid.shape, \n",
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 Desicion Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# hyperparameter tuning\n",
    "depths = range(1 , 25, 2)\n",
    "depth_mae = dict()\n",
    "for depth in depths:\n",
    "  clf = DecisionTreeClassifier(max_depth = depth)\n",
    "  clf.fit(x_train, y_train)\n",
    "  y_pred = clf.predict(x_valid)\n",
    "  acc = calculate_acc(y_pred, y_valid)\n",
    "  depth_mae[depth] = acc\n",
    "plt.plot(list(depth_mae.keys()), list(depth_mae.values()))\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Test ACC')\n",
    "\n",
    "# usage\n",
    "best_max_depth = max(depth_mae, key = depth_mae.get)\n",
    "clf = DecisionTreeClassifier(max_depth = best_max_depth )\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "acc = calculate_acc(y_pred, y_test)\n",
    "\n",
    "total_result['decision_tree'] = acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.16s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ruhy/projects/data_mining_uni/classification.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ruhy/projects/data_mining_uni/classification.ipynb#ch0000010?line=9'>10</a>\u001b[0m   k_scores[k] \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mscore(x_valid, y_valid)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ruhy/projects/data_mining_uni/classification.ipynb#ch0000010?line=11'>12</a>\u001b[0m \u001b[39m# plot\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ruhy/projects/data_mining_uni/classification.ipynb#ch0000010?line=12'>13</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(k_scores\u001b[39m.\u001b[39;49mkey(), k_scores\u001b[39m.\u001b[39mvlaues(), \u001b[39m'\u001b[39m\u001b[39mg\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ruhy/projects/data_mining_uni/classification.ipynb#ch0000010?line=13'>14</a>\u001b[0m plt\u001b[39m.\u001b[39mlegend([\u001b[39m'\u001b[39m\u001b[39mTest\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ruhy/projects/data_mining_uni/classification.ipynb#ch0000010?line=14'>15</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mNumber of Neighbors\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'key'"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Tuning hyperparameter k\n",
    "acc_train = []\n",
    "k_scores = {}\n",
    "k_range = range(1, 10, 5)\n",
    "for k in tqdm(k_range):\n",
    "  clf = KNeighborsClassifier(n_neighbors=k)\n",
    "  clf.fit(x_train, y_train)\n",
    "  k_scores[k] = clf.score(x_valid, y_valid)\n",
    "  \n",
    "# plot\n",
    "plt.plot(k_scores.keys(), k_scores.vlaues(), 'g')\n",
    "plt.legend(['Test'])\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "best_k = max(k_scores, key=k_scores.get)\n",
    "print(best_k)\n",
    "clf = KNeighborsClassifier(n_neighbors= best_k)\n",
    "clf.fit(x_train, y_train)\n",
    "score = clf.score(x_test, y_test)\n",
    "\n",
    "\n",
    "total_result['knn'] = score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruhy/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ruhy/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ruhy/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ruhy/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ruhy/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_X_train = scaler.fit_transform(x_train)\n",
    "scaled_X_test = scaler.fit_transform(x_test)\n",
    "\n",
    "c_scores = dict()\n",
    "# hype tunning and plot\n",
    "for c in range(1,5):\n",
    "  clf = LogisticRegression(C= c )\n",
    "  clf.fit(x_train, y_train)\n",
    "  score = clf.score(x_valid, y_valid)\n",
    "  c_scores[c] = score\n",
    "  \n",
    "#TODO:\n",
    "plt.plot(c_scores.keys(), c_scores.values() , 'g')\n",
    "plt.legend(['Test'])\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "\n",
    "# usage\n",
    "best_c = max(c_scores, key = c_scores.get)\n",
    "clf = LogisticRegression(C = best_c)\n",
    "clf.fit(x_train, y_train)\n",
    "score = clf.score(x_test, y_test) \n",
    "total_result['Logistic_Regression'] = score\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [03:00<27:06, 180.71s/it]"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "c_arr = [0.001, 0.01, 0.1, 1, 10, 1e2, 1e3, 1e4, 1e5, 1e6]\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "hyperpara = {}\n",
    "for C in tqdm(c_arr):\n",
    "    svc = SVC(C=C)\n",
    "    svc.fit(x_train, y_train)\n",
    "\n",
    "    # train_acc.append(svc.score(x_valid, y_valid))\n",
    "    score = svc.score(x_valid, y_valid)\n",
    "    type(score)\n",
    "    test_acc.append(score)\n",
    "    hyperpara[C] = score\n",
    "total_result['SVM'] = max(test_acc)\n",
    "    # plot_desicion_boundary(X, y, svc, title=f\"C={C}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for hyper parametter accuracy \n",
    "plt.plot(np.log10(c_arr), train_acc, 'r')\n",
    "plt.plot(np.log10(c_arr), test_acc, 'b')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.xlabel('log(C)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 11139 points : 3318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Naive_Bayes': 70.2127659574468}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(x_train, y_train).predict(x_valid)\n",
    "# total_true = int((y_test != y_pred).sum())\n",
    "len_train  = x_test.shape[0]\n",
    "total_trues = (y_valid != y_pred).sum()\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "      % (len_train, total_trues))\n",
    "total_result['Naive_Bayes'] = (len_train - total_trues) / len_train * 100\n",
    "total_result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_valid, y_valid)\n",
    "total_result['Random_Forest'] = clf.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter : n_estiamtors (the number of trees)\n",
    "trees = []\n",
    "scores = []\n",
    "for i in range(100, 1001, 200 ):\n",
    "    clf = RandomForestClassifier(random_state=0, n_estimators = i)\n",
    "    clf.fit(x_train, y_train)\n",
    "    score = clf.score(x_valid, y_valid)\n",
    "    trees.append(i)\n",
    "    scores.append(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ruhy/projects/data_mining_uni/classification.ipynb Cell 23'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ruhy/projects/data_mining_uni/classification.ipynb#ch0000033?line=0'>1</a>\u001b[0m \u001b[39m'\u001b[39m\u001b[39mthe best e_estimator number is : \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m leads to \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m% a\u001b[39;00m\u001b[39mccuracy \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ruhy/projects/data_mining_uni/classification.ipynb#ch0000033?line=1'>2</a>\u001b[0m     \u001b[39mmax\u001b[39m(\u001b[39mlist\u001b[39m(scores)), \u001b[39mlist\u001b[39m(trees)[\u001b[39mlist\u001b[39;49m(scores)\u001b[39m.\u001b[39;49mindex(\u001b[39mlist\u001b[39;49m(scores))]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ruhy/projects/data_mining_uni/classification.ipynb#ch0000033?line=2'>3</a>\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "'the best e_estimator number is : {} leads to {}% accuracy '.format(\n",
    "    max(list(scores)), list(trees)[list(scores).index(list(scores))]\n",
    ")\n",
    "# [print(type(i)) for i in scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#6 Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#train \n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# use\n",
    "y_pred = clf.predict(x_valid)\n",
    "score = calculate_acc(y_pred, y_valid)\n",
    "f'the score of adaboos is {score}'\n",
    "total_result['Adaboost'] = score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#7 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Naive_Bayes': 70.2127659574468,\n",
       " 'Random_Forest': 0.9305144088338271,\n",
       " 'Adaboost': 0.7566208815872161,\n",
       " 'LightGBM': 0.7959421851153604}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "clf = LGBMClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "score = calculate_acc(y_pred, y_test)\n",
    "total_result['LightGBM'] = score\n",
    "total_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
